---
title: "There is hope - despite everything"
kind: article
created_at: 2007-02-08 21:34:00
author: fredrik
tags: ruby, java, web2.0, software development, design patterns
---
  <p>My first high level bit will be about the state of the software industry related to my own history as just a programmer. I will write a little in this post about several things that has been or will become important for me.</p><p>Next month I have worked in the software industry for 10 years which I think is an extraordinary accomplishment. (Party someone???) The first 3 years I worked for a product vendor into logistics and supply chain management and after that I have been a consultant working for myself and for others in different manners. I have been so tired of the way we build software so many times but still have not managed to do something else. I probably like it too much despite all the shortcomings. (And - to be honest - the pay is better than starting all over with some new trade.) Only on a few occasions have I been on projects that actually both produced usable software and also managed to produce beautiful software. With beautiful I mean well structured, purposeful, poetic and well written source code producing human user interfaces that empowers the user rather than scares them away. Instead of complaining more about this misery I would like to point out some things that made things look brighter.</p><p>Patterns are a pretty old concept now. I read a lot about them in the late 90s and got lots of inspiration from this nice way of talking about software. (I also read the bible by Christopher Alexander on building real houses. Brilliant book.) The design patterns written by the gang of four has become the common vocabulary for most developers. A problem is that a good developer uses design and code patterns pretty much without thinking about whether it is a pattern or not. A mediocre developer may try to use patterns but may still mess things up badly. Patterns used in the wrong places may be worse than not using patterns at all. (Oops - back to complaining....) The community of the original <a href="http://c2.com/cgi/wiki?WelcomeVisitors">wiki</a> created by Ward Cunningham gave me lot of inspiration during these early years.</p><p>It was also here that I first got in touch with eXtreme Programming and the ideas of Kent Beck among others. It was not a coincidence that approximately the same people that came up with design patterns also were the driving force behind the XP movement - maybe the freshest thing that has happened to software development during these 10 years. XP may be fundamentalist and way to extreme but it made way for the other agile processes - some of them already existing when XP appeared. I have been particularly fond of <a href="http://alistair.cockburn.us/">Alistair Cockburns</a> work on the Crystal method. He groks that the process needs to be tailored to each projects specific needs. Depending on the project scope, the product risk and available resources the process should be different for each project. &quot;It is the least methodology that could possibly work.&quot;</p><p>It may be a bit late to make some cheerful noise about Web 2.0 but I will nevertheless. I still remember the strange feeling of using Mosaic to surf the then tiny web from the computer labs of the <a href="http://www.kth.se/">Royal Institute of Technology</a> in 1994. It was not so much the actual content but the fact that it was live data from other countries (mostly US one may suspect). A new world with new possibilities was upon us all. In the beginning it was mostly about publishing information. Interaction was rare and involved the complicated <a href="http://www.w3.org/CGI/">Common Gateway Interface</a>. The first years filled with experiments. Anyone remember the abundant use of the <a href="http://www.siteexperts.com/tips/html/ts12/page1.asp">blink tag</a>? Or all these <a href="http://www.nepthys.com/textures/">colorful backgrounds</a> making any text on pages unreadable? And when animated gifs appeared there was a <a href="http://www.horton-szar.net/clipart/construction.php">construction worker</a> on every web page that wasn&#39;t done yet. The playfulness disappeared with the dot com years. At the same time the web turned ugly. Many web pages still has the dot com look - many of them in a state of decay. During these years companies started to think about maybe integrating the web with backend systems and this was possibly the best thing that started to happen during these dark years. Today there are no airlines without an online booking system - most of them pretty good. Some other experiments didn&#39;t work. Selling groceries over the net - for example - has not been overly successful. One strange side effect of the dot com era was that many large organizations turned to web technology for all their user interfaces. Even today with all the Web 2.0 stuff around it is hard to imagine a web client that can not be done more efficiently with a rich client. I would not consider hacking Java in a web client for example. Today Web 2.0 with its &quot;just enough&quot; interfaces brings new hope to a tired developer.</p><p>For some years I have been planning to abandon programming completely, not being satisfied with web client development with Java server technology. Last year I tried <a href="http://www.rubyonrails.org/">Ruby on Rails</a> and fell for both the language and the framework at once. All the redundancies with Java programming was removed in one sweep. Consider the difference between typing:<br /><pre>String someText = &quot;some text&quot;;</pre>in Java and the Ruby equivalent:<pre>someText = &quot;some text&quot;</pre>The difference is one word - &quot;String&quot; - that confuses the code line. Any developer knows that &quot;some text&quot; is a string. Stating it like this makes the assumption that &quot;some text&quot; may be something else. We need to distinguish this use of &quot;some text&quot; with the identifier String. The String does not add value or meaning to the code. (And honestly - what exactly is the point with semicolons? That character doesn&#39;t communicate.) The only point with a strongly typed language is that more tests are done at compile time. But if all programs have proper unit tests they would surely find a type conversion error and hence the need for strongly typed languages fade away. And we may all write less code for more functionality in the future.</p><p>&nbsp;</p>